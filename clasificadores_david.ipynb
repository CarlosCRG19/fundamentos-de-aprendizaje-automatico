{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta,abstractmethod\n",
    "\n",
    "\n",
    "class Clasificador:\n",
    "  \n",
    "  # Clase abstracta\n",
    "  __metaclass__ = ABCMeta\n",
    "  \n",
    "  # Metodos abstractos que se implementan en casa clasificador concreto\n",
    "  @abstractmethod\n",
    "  # TODO: esta funcion debe ser implementada en cada clasificador concreto. Crea el modelo a partir de los datos de entrenamiento\n",
    "  # datosTrain: matriz numpy o dataframe con los datos de entrenamiento\n",
    "  # nominalAtributos: array bool con la indicatriz de los atributos nominales\n",
    "  # diccionario: array de diccionarios de la estructura Datos utilizados para la codificacion de variables discretas\n",
    "  def entrenamiento(self,datosTrain,nominalAtributos,diccionario):\n",
    "    pass\n",
    "  \n",
    "  \n",
    "  @abstractmethod\n",
    "  # TODO: esta funcion debe ser implementada en cada clasificador concreto. Devuelve un numpy array con las predicciones\n",
    "  # datosTest: matriz numpy o dataframe con los datos de validaci�n\n",
    "  # nominalAtributos: array bool con la indicatriz de los atributos nominales\n",
    "  # diccionario: array de diccionarios de la estructura Datos utilizados para la codificacion de variables discretas\n",
    "  # devuelve un numpy array o vector con las predicciones (clase estimada para cada fila de test)\n",
    "  def clasifica(self,datosTest,nominalAtributos,diccionario):\n",
    "    pass\n",
    "  \n",
    "  \n",
    "  # Obtiene el numero de aciertos y errores para calcular la tasa de fallo\n",
    "  # TODO: implementar\n",
    "  def error(self,datos,pred):\n",
    "    # Aqui se compara la prediccion (pred) con las clases reales y se calcula el error\n",
    "    # devuelve el error\n",
    "    accuracy = metrics.accuracy_score(datos, pred)\n",
    "    return 1-accuracy\n",
    "    \n",
    "    \n",
    "  # Realiza una clasificacion utilizando una estrategia de particionado determinada\n",
    "  # TODO: implementar esta funcion\n",
    "  def validacion(self,particionado,dataset,clasificador,seed=None):\n",
    "    \n",
    "    # Creamos las particiones siguiendo la estrategia llamando a particionado.creaParticiones\n",
    "    # - Para validacion cruzada: en el bucle hasta nv entrenamos el clasificador con la particion de train i\n",
    "    # y obtenemos el error en la particion de test i\n",
    "    # - Para validacion simple (hold-out): entrenamos el clasificador con la particion de train\n",
    "    # y obtenemos el error en la particion test. Otra opci�n es repetir la validaci�n simple un n�mero especificado de veces, obteniendo en cada una un error. Finalmente se calcular�a la media.\n",
    "    # devuelve el vector con los errores por cada partici�n\n",
    "    \n",
    "    # pasos\n",
    "    # crear particiones\n",
    "    # inicializar vector de errores\n",
    "    # for cada partici�n\n",
    "    #     obtener datos de train\n",
    "    #     obtener datos de test\n",
    "    #     entrenar sobre los datos de train\n",
    "    #     obtener prediciones de los datos de test (llamando a clasifica)\n",
    "    #     a�adir error de la partici�n al vector de errores\n",
    "\t  pass  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClasificadorNaiveBayes_heart(Clasificador):\n",
    "    \n",
    "    \n",
    "    def entrenamiento(self, datosTrain, nominalAtributos, diccionario):\n",
    "\n",
    "####### encoder\n",
    "        nominales =[]\n",
    "        #nominales[nominales.append(datosTrain.iat[0, idx]) for idx in nominalAtributos if nominalAtributos[idx] == True]\n",
    "        for i in nominalAtributos:\n",
    "            if nominalAtributos[i] == True:\n",
    "                nominales.append(datosTrain.iat[0, i])\n",
    "        encoder = OneHotEncoder(drop='first')\n",
    "        self.datos = encoder.fit_transform(self.datos[nominales])\n",
    "#######\n",
    "\n",
    "        l_col = len(datosTrain.columns) - 1\n",
    "        y_datos = datosTrain[datosTrain.columns[l_col]]\n",
    "        X_datos = datosTrain.drop(datosTrain.columns[l_col], axis=1)\n",
    "\n",
    "        NB_gauss = GaussianNB()\n",
    "        NB_gauss.fit(X_datos, y_datos)\n",
    "    def clasifica(self, datosTest, nominalAtributos, diccionario):\n",
    "        \n",
    "        l_col = len(datosTest.columns) - 1\n",
    "        y_datos = datosTest[datosTest.columns[l_col]]\n",
    "        X_datos = datosTest.drop(datosTest.columns[l_col], axis=1)\n",
    "\n",
    "        pred = NB_gauss.predict(X_datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dhuff\\Desktop\\fundamentos-de-aprendizaje-automatico\\clasificadores_david.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         accuracy \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy \u001b[39m\u001b[39m%\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, accuracy)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m classifier \u001b[39m=\u001b[39m ClasificadorNaiveBayes_heart()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m classifier\u001b[39m.\u001b[39mcalculate_accuracy()\n",
      "\u001b[1;32mc:\\Users\\dhuff\\Desktop\\fundamentos-de-aprendizaje-automatico\\clasificadores_david.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatos \u001b[39m=\u001b[39m Datos(\u001b[39m\"\u001b[39;49m\u001b[39mheart.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mdatos\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m#nominals = [\"Sex\", \"ChestPainType\", \"FastingBS\", \"Resting ECG\", \"ExerciseAngina\", \"ST-Slope\"]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m#encoder = OneHotEncoder(drop='first')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m#self.datos = encoder.fit_transform(self.datos[nominals])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dhuff/Desktop/fundamentos-de-aprendizaje-automatico/clasificadores_david.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     l_col \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatos\u001b[39m.\u001b[39mcolumns) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "class ClasificadorNaiveBayes_heart:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.datos = Datos(\"heart.csv\").datos\n",
    "        #nominals = [\"Sex\", \"ChestPainType\", \"FastingBS\", \"Resting ECG\", \"ExerciseAngina\", \"ST-Slope\"]\n",
    "        #encoder = OneHotEncoder(drop='first')\n",
    "        #self.datos = encoder.fit_transform(self.datos[nominals])\n",
    "\n",
    "\n",
    "        l_col = len(self.datos.columns) - 1\n",
    "        self.y = self.datos[self.datos.columns[l_col]]\n",
    "        self.X = self.datos.drop(self.datos.columns[l_col], axis=1)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "\n",
    "        self.GNB = GaussianNB()\n",
    "        self.GNB.fit(self.X_train, self.y_train)\n",
    "\n",
    "        self.pred = self.GNB.predict(self.X_test)\n",
    "\n",
    "    def calculate_accuracy(self):\n",
    "        accuracy = metrics.accuracy_score(self.y_test, self.pred) * 100\n",
    "        print(\"Accuracy %:\", accuracy)\n",
    "    \n",
    "classifier = ClasificadorNaiveBayes_heart()\n",
    "classifier.calculate_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClasificadorNaiveBayes_ttt_multinominal:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
