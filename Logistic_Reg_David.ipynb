{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Datos:\n",
    "    datos: int\n",
    "    nominalAtributos: List[bool]\n",
    "\n",
    "    # Constructor: procesar el fichero para asignar correctamente las variables nominalAtributos, datos y diccionarios\n",
    "    def __init__(self, nombreFichero: str):\n",
    "        self.datosCrudos = pd.read_csv(nombreFichero)\n",
    "        self.datos = self.datosCrudos.copy()\n",
    "\n",
    "        self.nominalAtributos = []\n",
    "        self.diccionarios = {}\n",
    "\n",
    "        for columna in self.datos.columns:\n",
    "            if self._es_nominal(columna):\n",
    "                self.nominalAtributos.append(True)\n",
    "                self.diccionarios[columna] = self._generar_mapeo(columna)\n",
    "                self.datos[columna] = self._reemplazar_valores(columna)\n",
    "            elif self._es_numerico(columna):\n",
    "                self.nominalAtributos.append(False)\n",
    "                self.diccionarios[columna] = {}\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"La columna '{columna}' contiene valores que no son nominales ni enteros/decimales.\"\n",
    "                )\n",
    "\n",
    "    def _es_nominal(self, columna: str) -> bool:\n",
    "        # es verdadero si es la columna objetivo o si sus valores son nominales\n",
    "        return columna.lower() == \"class\" or self.datos[columna].dtype.name == \"object\"\n",
    "\n",
    "    def _es_numerico(self, columna: str) -> bool:\n",
    "        # es verdadero si los valores son un n�meros enteros o reales\n",
    "        return self.datos[columna].dtype.name in [\"int64\", \"float64\"]\n",
    "\n",
    "    def _generar_mapeo(self, columna_nominal: str):\n",
    "        # se extraen los valores �nicos de la columna y se sortean lexicograficamente\n",
    "        valores = [str(valor) for valor in self.datos[columna_nominal].unique()]\n",
    "        valores = sorted(valores)\n",
    "\n",
    "        return {valor: indice for indice, valor in enumerate(valores)}\n",
    "\n",
    "    def _reemplazar_valores(self, columna_nominal: str) -> pd.Series:\n",
    "        mapeo = self.diccionarios[columna_nominal]\n",
    "        return self.datos[columna_nominal].map(lambda valor: mapeo[str(valor)])\n",
    "\n",
    "    # Devuelve el subconjunto de los datos cuyos �ndices se pasan como argumento\n",
    "    def extraeDatos(self, idx: List[int]):\n",
    "        return self.datos.iloc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from math import floor\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Particion:\n",
    "    # Esta clase mantiene la lista de indices de Train y Test para cada particion del conjunto de particiones\n",
    "    def __init__(self, indicesTrain: List[int] = [], indicesTest: List[int] = []):\n",
    "        self.indicesTrain = indicesTrain\n",
    "        self.indicesTest = indicesTest\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"indices train: {self.indicesTrain}. indices test: {self.indicesTest}\"\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "class EstrategiaParticionado:\n",
    "    # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "    particiones: List[Particion]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.particiones = []\n",
    "\n",
    "    # Atributos: deben rellenarse adecuadamente para cada estrategia concreta. Se pasan en el constructor\n",
    "\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada estrategia concreta\n",
    "    def creaParticiones(self, datos: pd.DataFrame, seed: int = None) -> List[Particion]:\n",
    "        pass\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "class ValidacionSimple(EstrategiaParticionado):\n",
    "    def __init__(self, numeroEjecuciones: int, proporcionTest: int):\n",
    "        super().__init__()\n",
    "        self.numeroEjecuciones = numeroEjecuciones\n",
    "        self.proporcionTest = proporcionTest\n",
    "\n",
    "    # Crea particiones segun el metodo tradicional de division de los datos segun el porcentaje deseado y el numero de ejecuciones deseado\n",
    "    # Devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self, datos: pd.DataFrame, seed: int = 42) -> List[Particion]:\n",
    "        n_filas = datos.shape[0]\n",
    "        indices = list(range(n_filas))\n",
    "\n",
    "        random.seed(seed)\n",
    "\n",
    "        for _ in range(self.numeroEjecuciones):\n",
    "            random.shuffle(indices)\n",
    "\n",
    "            # se calcula el numero de ejemplos que se usaran como conjunto de prueba\n",
    "            proporcion = floor(self.proporcionTest / 100 * n_filas)\n",
    "\n",
    "            indices_train = indices[proporcion:]\n",
    "            indices_test = indices[:proporcion]\n",
    "\n",
    "            particion = Particion(indicesTrain=indices_train, indicesTest=indices_test)\n",
    "\n",
    "            self.particiones.append(particion)\n",
    "\n",
    "        return self.particiones\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "class ValidacionCruzada(EstrategiaParticionado):\n",
    "    def __init__(self, numeroParticiones: int):\n",
    "        super().__init__()\n",
    "        self.numeroParticiones = numeroParticiones\n",
    "\n",
    "    # Crea particiones segun el metodo de validacion cruzada.\n",
    "    # El conjunto de entrenamiento se crea con las nfolds-1 particiones y el de test con la particion restante\n",
    "    # Esta funcion devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self, datos: pd.DataFrame, seed: int = None) -> List[Particion]:\n",
    "        n_filas = datos.shape[0]\n",
    "        indices = list(range(n_filas))\n",
    "\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        longitud_fold = n_filas // self.numeroParticiones\n",
    "        resto = n_filas % self.numeroParticiones\n",
    "\n",
    "        inicio = 0\n",
    "\n",
    "        for i in range(self.numeroParticiones):\n",
    "            fin = inicio + longitud_fold\n",
    "\n",
    "            # para las longitudes que no son divisibles enteramente por el numero\n",
    "            # de particiones los primeros folds tienen una longitud extra.\n",
    "            # e.g. datos = [1,2,3,4,5]; particiones = 3; folds = [[1,2], [3,4], [5]]\n",
    "            if i < resto:\n",
    "                fin += 1\n",
    "\n",
    "            fin = min(fin, n_filas)\n",
    "\n",
    "            # se construyen los indices para las particiones.\n",
    "            # Los indices para training son todos aquellos que no pertenecen\n",
    "            # a los indices de testing\n",
    "            indices_test = indices[inicio:fin]\n",
    "            indices_train = [\n",
    "                indices[j] for j in range(n_filas) if j not in indices_test\n",
    "            ]\n",
    "\n",
    "            particion = Particion(indicesTrain=indices_train, indicesTest=indices_test)\n",
    "\n",
    "            self.particiones.append(particion)\n",
    "\n",
    "            inicio = fin\n",
    "\n",
    "        return self.particiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos: 87.61%\n",
      "    Prediccion  Clase verdadera\n",
      "0          1.0              1.0\n",
      "1          0.0              0.0\n",
      "2          0.0              0.0\n",
      "3          0.0              0.0\n",
      "4          0.0              0.0\n",
      "5          0.0              0.0\n",
      "6          1.0              1.0\n",
      "7          0.0              0.0\n",
      "8          1.0              1.0\n",
      "9          1.0              1.0\n",
      "10         0.0              0.0\n",
      "11         0.0              0.0\n",
      "12         1.0              1.0\n",
      "13         1.0              1.0\n",
      "14         0.0              0.0\n",
      "15         0.0              0.0\n",
      "16         1.0              1.0\n",
      "17         0.0              0.0\n",
      "18         0.0              0.0\n",
      "19         1.0              1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclass ClasificadorRegresionLogisticaSkLearn:\\n    atributos = datos.iloc[:, :-1]\\n    objetivo = datos[:, -1]\\n\\n    X_train, X_test, y_train, y_test = train_test_split(atributos, objetivo, test_size=0.2, random_state=42)\\n    scaler = StandardScaler()\\n    X_train_scaled = scaler.fit_transform(X_train)\\n    X_test_scaled = scaler.transform(X_test)\\n\\n    modelo = LogisticRegression()\\n    modelo.fit(X_train_scaled, y_train)\\n    predicciones = modelo.predict(X_test_scaled)\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import Clasificador\n",
    "\n",
    "class ClasificadorRegresionLogistica:\n",
    "\n",
    "    def __init__(self, k_apre):\n",
    "        self.k_apre = k_apre\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def sigmoid(self, w_v, x_v):\n",
    "        x = np.array(x_v)[0]\n",
    "        w = np.array(w_v)[0]\n",
    "        return 1 / (1 + np.exp(-w*x))\n",
    "\n",
    "\n",
    "    def actualiza_w(self, w, x):\n",
    "        t = x.iloc[-1]\n",
    "        #print(t)\n",
    "        x = np.array(x.iloc[:-1])\n",
    "        return w - x * (self.sigmoid(w, x) - t) * self.k_apre\n",
    "    \n",
    "    def entrenamiento(self, epocas, datosTrain):\n",
    "        # crea umbral\n",
    "        w = [random.uniform(-0.5, 0.5) for _ in datosTrain.iloc[:,:-1]]\n",
    "\n",
    "        # normalizar los datos\n",
    "        #for col in datosTrain.columns:\n",
    "         #   datosTrain[col] = datosTrain[col] / datosTrain[col].abs().max()\n",
    "\n",
    "        for _ in range(0, epocas):\n",
    "            for _, dato in datosTrain.iterrows():\n",
    "                #verosimilitud_clase1 = self.sigmoid(w, dato[:-1])\n",
    "                w = self.actualiza_w(w, dato)\n",
    "        return w\n",
    "    \n",
    "    def clasifica(self, datosTest, w):\n",
    "        # normalizar los datos\n",
    "        #for col in datosTest.columns:\n",
    "         #   datosTest[col] = datosTest[col] / datosTest[col].abs().max()\n",
    "        \n",
    "        precision = 0\n",
    "        n_datosTest = len(datosTest)\n",
    "\n",
    "\n",
    "\n",
    "        resultados = pd.DataFrame(columns=[\"Prediccion\", \"Clase verdadera\"])\n",
    "\n",
    "        for _, dato in datosTest.iterrows():\n",
    "            \n",
    "            X_test = dato.iloc[:-1]\n",
    "            y_test = dato.iloc[-1]\n",
    "            prediccion = round(self.sigmoid(w, X_test))\n",
    "\n",
    "            if prediccion == y_test:\n",
    "                precision += 1\n",
    "            \n",
    "            \n",
    "            resultados.loc[len(resultados)] = [prediccion, y_test]\n",
    "        \n",
    "        print(f\"Aciertos: {round(100*precision/n_datosTest, 2)}%\")\n",
    "        return resultados\n",
    "\n",
    "\n",
    "\n",
    "def resultados_log(k_apre, epocas):\n",
    "    datos = Datos(\"wdbc.csv\")\n",
    "    \n",
    "    # normalizar los datos\n",
    "    for col in datos.datos.iloc[:, :-1]:\n",
    "        #datos.datos[col] = datos.datos[col] / datos.datos[col].abs().max()\n",
    "        datos.datos[col] = (datos.datos[col] - datos.datos[col].mean()) / datos.datos[col].std()\n",
    "    \n",
    "    validacion = ValidacionSimple(3, 20)\n",
    "    particionado = validacion.creaParticiones(datos.datos)\n",
    "    \n",
    "\n",
    "    for particion in particionado:\n",
    "        datos_test = datos.extraeDatos(particion.indicesTest)\n",
    "        datos_train = datos.extraeDatos(particion.indicesTrain)\n",
    "\n",
    "    clasificador = ClasificadorRegresionLogistica(k_apre)\n",
    "\n",
    "    hiperplano = clasificador.entrenamiento(epocas, datos_train)\n",
    "\n",
    "    res = clasificador.clasifica(datos_test, hiperplano)\n",
    "\n",
    "    print(res.head(20))\n",
    "    #print(res.loc[res['Prediccion'] >= 0.543])\n",
    "\n",
    "resultados_log(4, 10)\n",
    "\n",
    "\"\"\"\n",
    "class ClasificadorRegresionLogisticaSkLearn:\n",
    "    atributos = datos.iloc[:, :-1]\n",
    "    objetivo = datos[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(atributos, objetivo, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    modelo = LogisticRegression()\n",
    "    modelo.fit(X_train_scaled, y_train)\n",
    "    predicciones = modelo.predict(X_test_scaled)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
