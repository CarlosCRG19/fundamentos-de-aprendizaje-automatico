{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Datos:\n",
    "    datos: int\n",
    "    nominalAtributos: List[bool]\n",
    "    \n",
    "\n",
    "    # Constructor: procesar el fichero para asignar correctamente las variables nominalAtributos, datos y diccionarios\n",
    "    def __init__(self, nombreFichero: str):\n",
    "        self.datosCrudos = pd.read_csv(nombreFichero)\n",
    "        self.datos = self.datosCrudos.copy()\n",
    "\n",
    "        self.nominalAtributos = []\n",
    "        self.diccionarios = {}\n",
    "\n",
    "        for columna in self.datos.columns:\n",
    "            if self._es_nominal(columna):\n",
    "                self.nominalAtributos.append(True)\n",
    "                self.diccionarios[columna] = self._generar_mapeo(columna)\n",
    "                self.datos[columna] = self._reemplazar_valores(columna)\n",
    "            elif self._es_numerico(columna):\n",
    "                self.nominalAtributos.append(False)\n",
    "                self.diccionarios[columna] = {}\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"La columna '{columna}' contiene valores que no son nominales ni enteros/decimales.\"\n",
    "                )\n",
    "\n",
    "    def _es_nominal(self, columna: str) -> bool:\n",
    "        # es verdadero si es la columna objetivo o si sus valores son nominales\n",
    "        return columna.lower() == \"class\" or self.datos[columna].dtype.name == \"object\"\n",
    "\n",
    "    def _es_numerico(self, columna: str) -> bool:\n",
    "        # es verdadero si los valores son un n�meros enteros o reales\n",
    "        return self.datos[columna].dtype.name in [\"int64\", \"float64\"]\n",
    "\n",
    "    def _generar_mapeo(self, columna_nominal: str):\n",
    "        # se extraen los valores �nicos de la columna y se sortean lexicograficamente\n",
    "        valores = [str(valor) for valor in self.datos[columna_nominal].unique()]\n",
    "        valores = sorted(valores)\n",
    "\n",
    "        return {valor: indice for indice, valor in enumerate(valores)}\n",
    "\n",
    "    def _reemplazar_valores(self, columna_nominal: str) -> pd.Series:\n",
    "        mapeo = self.diccionarios[columna_nominal]\n",
    "        return self.datos[columna_nominal].map(lambda valor: mapeo[str(valor)])\n",
    "\n",
    "    # Devuelve el subconjunto de los datos cuyos �ndices se pasan como argumento\n",
    "    def extraeDatos(self, idx: List[int]):\n",
    "        return self.datos.iloc[idx]\n",
    "    \n",
    "    def one_hot_encode(self):\n",
    "        nominales = [self.datos.columns[i] for i in range(0, len(self.datos.columns)-1) if self.nominalAtributos[i] == True]\n",
    "\n",
    "        self.datos = pd.get_dummies(self.datos, columns=nominales, drop_first=True)\n",
    "        return self \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from math import floor\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Particion:\n",
    "    # Esta clase mantiene la lista de indices de Train y Test para cada particion del conjunto de particiones\n",
    "    def __init__(self, indicesTrain: List[int] = [], indicesTest: List[int] = []):\n",
    "        self.indicesTrain = indicesTrain\n",
    "        self.indicesTest = indicesTest\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"indices train: {self.indicesTrain}. indices test: {self.indicesTest}\"\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "class EstrategiaParticionado:\n",
    "    # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "    particiones: List[Particion]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.particiones = []\n",
    "\n",
    "    # Atributos: deben rellenarse adecuadamente para cada estrategia concreta. Se pasan en el constructor\n",
    "\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion deben ser implementadas en cada estrategia concreta\n",
    "    def creaParticiones(self, datos: pd.DataFrame, seed: int = None) -> List[Particion]:\n",
    "        pass\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "class ValidacionSimple(EstrategiaParticionado):\n",
    "    def __init__(self, numeroEjecuciones: int, proporcionTest: int):\n",
    "        super().__init__()\n",
    "        self.numeroEjecuciones = numeroEjecuciones\n",
    "        self.proporcionTest = proporcionTest\n",
    "\n",
    "    # Crea particiones segun el metodo tradicional de division de los datos segun el porcentaje deseado y el numero de ejecuciones deseado\n",
    "    # Devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self, datos: pd.DataFrame, seed: int = 42) -> List[Particion]:\n",
    "        n_filas = datos.shape[0]\n",
    "        indices = list(range(n_filas))\n",
    "\n",
    "        random.seed(seed)\n",
    "\n",
    "        for _ in range(self.numeroEjecuciones):\n",
    "            random.shuffle(indices)\n",
    "\n",
    "            # se calcula el numero de ejemplos que se usaran como conjunto de prueba\n",
    "            proporcion = floor(self.proporcionTest / 100 * n_filas)\n",
    "\n",
    "            indices_train = indices[proporcion:]\n",
    "            indices_test = indices[:proporcion]\n",
    "\n",
    "            particion = Particion(indicesTrain=indices_train, indicesTest=indices_test)\n",
    "\n",
    "            self.particiones.append(particion)\n",
    "\n",
    "        return self.particiones\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "class ValidacionCruzada(EstrategiaParticionado):\n",
    "    def __init__(self, numeroParticiones: int):\n",
    "        super().__init__()\n",
    "        self.numeroParticiones = numeroParticiones\n",
    "\n",
    "    # Crea particiones segun el metodo de validacion cruzada.\n",
    "    # El conjunto de entrenamiento se crea con las nfolds-1 particiones y el de test con la particion restante\n",
    "    # Esta funcion devuelve una lista de particiones (clase Particion)\n",
    "    def creaParticiones(self, datos: pd.DataFrame, seed: int = None) -> List[Particion]:\n",
    "        n_filas = datos.shape[0]\n",
    "        indices = list(range(n_filas))\n",
    "\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            random.shuffle(indices)\n",
    "\n",
    "        longitud_fold = n_filas // self.numeroParticiones\n",
    "        resto = n_filas % self.numeroParticiones\n",
    "\n",
    "        inicio = 0\n",
    "\n",
    "        for i in range(self.numeroParticiones):\n",
    "            fin = inicio + longitud_fold\n",
    "\n",
    "            # para las longitudes que no son divisibles enteramente por el numero\n",
    "            # de particiones los primeros folds tienen una longitud extra.\n",
    "            # e.g. datos = [1,2,3,4,5]; particiones = 3; folds = [[1,2], [3,4], [5]]\n",
    "            if i < resto:\n",
    "                fin += 1\n",
    "\n",
    "            fin = min(fin, n_filas)\n",
    "\n",
    "            # se construyen los indices para las particiones.\n",
    "            # Los indices para training son todos aquellos que no pertenecen\n",
    "            # a los indices de testing\n",
    "            indices_test = indices[inicio:fin]\n",
    "            indices_train = [\n",
    "                indices[j] for j in range(n_filas) if j not in indices_test\n",
    "            ]\n",
    "\n",
    "            particion = Particion(indicesTrain=indices_train, indicesTest=indices_test)\n",
    "\n",
    "            self.particiones.append(particion)\n",
    "\n",
    "            inicio = fin\n",
    "\n",
    "        return self.particiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart: \n",
      "Precision: 63.39%\n",
      "wdbc: \n",
      "Precision: 85.84%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import Clasificador\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class ClasificadorRegresionLogistica:\n",
    "\n",
    "    def __init__(self, k_apre, epocas):\n",
    "        self.k_apre = k_apre\n",
    "        self.epocas = epocas\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def sigmoid(self, w_v, x_v):\n",
    "        x = np.array(x_v)[0]\n",
    "        w = np.array(w_v)[0]\n",
    "        return 1 / (1 + np.exp(-w*x))\n",
    "\n",
    "\n",
    "    def actualiza_w(self, w, x):\n",
    "        t = x.iloc[-1]\n",
    "        x = np.array(x.iloc[:-1])\n",
    "        return w - x * (self.sigmoid(w, x) - t) * self.k_apre\n",
    "    \n",
    "    def entrenamiento(self, datosTrain):\n",
    "        # crea umbral\n",
    "        self.w = [random.uniform(-0.5, 0.5) for _ in datosTrain.iloc[:,:-1]]\n",
    "        verosimilitud_clase1 = 0\n",
    "\n",
    "        for _ in range(0, self.epocas):\n",
    "            for _, dato in datosTrain.iterrows():\n",
    "\n",
    "\n",
    "\n",
    "                #verosimilitud_clase1 = max(self.sigmoid(self.w, dato[:-1]), verosimilitud_clase1)\n",
    "                self.w = self.actualiza_w(self.w, dato)\n",
    "    \n",
    "    def clasifica(self, datosTest):\n",
    "        n_datosTest = len(datosTest)\n",
    "        preds = []\n",
    "        y_test = datosTest.iloc[:, -1]\n",
    "\n",
    "        for _, dato in datosTest.iterrows():\n",
    "            \n",
    "            X_dato = dato.iloc[:-1]\n",
    "            y_dato = dato.iloc[-1]\n",
    "            prediccion = round(self.sigmoid(self.w, X_dato))\n",
    "            #print(prediccion, \" \", y_dato)\n",
    "            preds.append(prediccion)\n",
    "            \n",
    "        aciertos = sum(p == t for p, t in zip(preds, y_test))    \n",
    "        \n",
    "        return f\"Precision: {round(100*aciertos/n_datosTest, 2)}%\"\n",
    "\n",
    "\n",
    "\n",
    "def resultados_log(fichero, k_apre, epocas):\n",
    "    datos = Datos(fichero)\n",
    "    datos = datos.one_hot_encode()\n",
    "\n",
    "    # normalizar los datos\n",
    "    for col in datos.datos.iloc[:, :-1]:\n",
    "        datos.datos[col] = (datos.datos[col] - datos.datos[col].mean()) / datos.datos[col].std()\n",
    "    \n",
    "    #validacion = ValidacionSimple(3, 20)\n",
    "    validacion = ValidacionCruzada(5)\n",
    "    particionado = validacion.creaParticiones(datos.datos)\n",
    "    \n",
    "\n",
    "    for particion in particionado:\n",
    "        datos_test = datos.extraeDatos(particion.indicesTest)\n",
    "        datos_train = datos.extraeDatos(particion.indicesTrain)\n",
    "\n",
    "    clasificador = ClasificadorRegresionLogistica(k_apre, epocas)\n",
    "\n",
    "    clasificador.entrenamiento(datos_train)\n",
    "\n",
    "    res = clasificador.clasifica(datos_test)\n",
    "\n",
    "    print(res)\n",
    "    #print(res.loc[res['Prediccion'] >= 0.543])\n",
    "\n",
    "print(\"heart: \")\n",
    "resultados_log(\"heart.csv\", 1, 10)\n",
    "print(\"wdbc: \")\n",
    "resultados_log(\"wdbc.csv\", 1, 10)\n",
    "\n",
    "\n",
    "class ClasificadorRegresionLogisticaSkLearn:\n",
    "    def __init__(self, k_apre = int, epocas = int):\n",
    "\n",
    "        self.k_apre = k_apre\n",
    "        self.epocas = epocas\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def entrenamiento(self, datosTrain):\n",
    "        X_train = datosTrain.iloc[:, :-1]\n",
    "        y_train = datosTrain.iloc[:, -1]\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        self.modelo = LogisticRegression()\n",
    "        self.modelo.fit(X_train, y_train)\n",
    "    \n",
    "    def clasifica(self, datosTest):\n",
    "        X_test = datosTest.iloc[:, :-1]\n",
    "        y_test = datosTest.iloc[:, -1]\n",
    "\n",
    "        X_test = self.scaler.transform(X_test)\n",
    "\n",
    "        preds = self.modelo.predict(X_test)\n",
    "        \n",
    "        aciertos = sum(p == t for p, t in zip(preds, y_test))\n",
    "\n",
    "        return f\"Precision: {round(100*aciertos/len(preds), 2)}%\"\n",
    "\n",
    "def resultados_log_sk(fichero, k_apre, epocas):\n",
    "    datos = Datos(fichero)\n",
    "    datos = datos.one_hot_encode()\n",
    "\n",
    "    clasificador = ClasificadorRegresionLogisticaSkLearn(k_apre, epocas)\n",
    "\n",
    "    validacion = ValidacionCruzada(5)\n",
    "    particionado = validacion.creaParticiones(datos.datos)\n",
    "    \n",
    "\n",
    "    for particion in particionado:\n",
    "        datos_test = datos.extraeDatos(particion.indicesTest)\n",
    "        datos_train = datos.extraeDatos(particion.indicesTrain)\n",
    "\n",
    "    clasificador.entrenamiento(datos_train)\n",
    "    res = clasificador.clasifica(datos_test)\n",
    "    print(res)\n",
    "\n",
    "print(\"heart con sklearn: \")\n",
    "resultados_log_sk(\"heart.csv\", 1, 5)\n",
    "print(\"wdbc.csv con sklearn:\")\n",
    "resultados_log_sk(\"wdbc.csv\", 1, 5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
